{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welcome-accused",
   "metadata": {},
   "source": "# Stage 2.0: NLP Exploratory Analysis - Wordclouds\n\nVisualization notebook for comparing review text between quality and non-quality reviews.\n\n**Input**: Stage 2 NLP output (2.5_lda) with review_text column  \n**Output**: Wordcloud visualizations comparing quality vs non-quality reviews\n\nQuality = reviews with useful/funny/cool votes (T2_CLS_ufc_>0 = True)"
  },
  {
   "cell_type": "markdown",
   "id": "dress-broad",
   "metadata": {},
   "source": "## Overview\n\nThis notebook creates wordclouds to visually compare the vocabulary used in:\n- **Quality reviews**: Reviews that received useful, funny, or cool votes\n- **Non-quality reviews**: Reviews with zero votes\n\nThe wordclouds help identify if there are obvious vocabulary differences between the two classes."
  },
  {
   "cell_type": "markdown",
   "id": "saved-flower",
   "metadata": {},
   "source": [
    "## Imports and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-oasis",
   "metadata": {},
   "outputs": [],
   "source": "# Common Libraries\nimport sys\nfrom pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Wordclouds\nfrom wordcloud import WordCloud, STOPWORDS\n\n# Add project root to path for imports\nsys.path.insert(0, str(Path.cwd().parent))\nfrom src.config import PathConfig\n\npd.set_option('display.float_format', lambda x: '%.5f' % x)"
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-cursor",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-november",
   "metadata": {},
   "outputs": [],
   "source": "# Load training data from Stage 2 NLP output\n# Using final LDA output which has all features, including review_text\ninput_dir = PathConfig.get_nlp_lda_dir()\nprint(f\"Reading from: {input_dir}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-calvin",
   "metadata": {},
   "outputs": [],
   "source": "# Read training data (only need review_text and target column for wordclouds)\ndf = pd.read_parquet(\n    input_dir / \"train.parquet\",\n    columns=[\"review_id\", \"review_text\", \"T2_CLS_ufc_>0\"]\n)\nprint(f\"Loaded {len(df):,} reviews\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-scanner",
   "metadata": {},
   "outputs": [],
   "source": "# Rename target column to simpler name for this notebook\ndf = df.rename(columns={\"T2_CLS_ufc_>0\": \"is_quality\"})\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-saturn",
   "metadata": {},
   "outputs": [],
   "source": "df.info()"
  },
  {
   "cell_type": "markdown",
   "id": "lasting-teaching",
   "metadata": {},
   "source": [
    "## Dataframe Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-settle",
   "metadata": {},
   "outputs": [],
   "source": "df.is_quality.value_counts()"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "systematic-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   review_id        10000 non-null  object\n",
      " 1   review_text      10000 non-null  object\n",
      " 2   target_ufc_bool  10000 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ambient-fortune",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5101\n",
       "False    4899\n",
       "Name: target_ufc_bool, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target_ufc_bool.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-cutting",
   "metadata": {},
   "source": [
    "## Splitting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-worthy",
   "metadata": {},
   "outputs": [],
   "source": "# Split corpus by quality label\ncorpus = df.review_text\nQ_corpus = df[df[\"is_quality\"] == True][\"review_text\"]\nNQ_corpus = df[df[\"is_quality\"] == False][\"review_text\"]\nprint(f'Corpus Size: Total:{len(corpus):,}, Quality:{len(Q_corpus):,}, Not Quality:{len(NQ_corpus):,}')"
  },
  {
   "cell_type": "markdown",
   "id": "editorial-kinase",
   "metadata": {},
   "source": [
    "## WordClouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-patch",
   "metadata": {},
   "source": [
    "### Wordcloud Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "empty-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-starter",
   "metadata": {},
   "source": [
    "#### Join Corpus Into One String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "registered-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_text = \" \".join(review for review in Q_corpus)\n",
    "NQ_text = \" \".join(review for review in NQ_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-method",
   "metadata": {},
   "source": [
    "### Make Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "small-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_wordcloud = WordCloud(stopwords=stopwords, background_color=\"cornflowerblue\", colormap=\"Set1\",\n",
    "                      collocations=False, color_func=lambda *args, **kwargs: \"black\",\n",
    "                      width=1000, height=1000).generate(Q_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "documentary-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "NQ_wordcloud = WordCloud(stopwords=stopwords, background_color=\"lightcoral\", colormap=\"Set1\",\n",
    "                      collocations=False, color_func=lambda *args, **kwargs: \"black\",\n",
    "                      width=1000, height=1000).generate(NQ_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-serum",
   "metadata": {},
   "source": [
    "### Save and Show Wordclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-microphone",
   "metadata": {},
   "outputs": [],
   "source": "# Create side-by-side wordcloud visualization\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 7))\n\nax1.imshow(Q_wordcloud)\nax1.axis(\"off\")\nax1.set_title(\"Quality Reviews\\n(has useful/funny/cool votes)\", fontsize=18, pad=10)\n\nax2.imshow(NQ_wordcloud)\nax2.axis(\"off\")\nax2.set_title(\"Non-Quality Reviews\\n(no votes)\", fontsize=18, pad=10)\n\nfig.suptitle(\"Yelp Review Text: Quality vs Non-Quality\", fontsize=22, y=1.02)\nfig.tight_layout(pad=2)\n\n# Uncomment to save\n# plt.savefig('../images/review_wordclouds.png', dpi=300, bbox_inches='tight')\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}